{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Hyperparameter Hunting with RBM and MLP\n",
    "\n",
    "```python\n",
    "# RBM hyperparameters (you CAN change these):\n",
    "rbm_is_continuous\t= True # roll dice?\n",
    "rbm_visible_size\t= 784 # depends on how many rbm layers\n",
    "rbm_hidden_size\t\t= 50 # primary variable\n",
    "rbm_batch_size\t\t= 10\n",
    "rbm_learn_rate\t\t= 0.01\n",
    "rbm_cd_steps\t\t= 1\n",
    "rbm_training_epochs = 100 # it is possible to overtrain depending on learning rate\n",
    "rbm_report_freq\t\t= 1 # just for convenience\n",
    "rbm_report_buffer\t= rbm_training_epochs\n",
    "# you probably want to hit around 350 coming out of the final rbm\n",
    "# power curve reduction?\n",
    "\n",
    "# MLP hyperparameters (you CAN change these):\n",
    "# more than 2 to 3 layers is prob not helpful\n",
    "mlp_layer_sizes\t\t= [ rbm_hidden_size, 20, 10 ] # always last is 10, always first is equal to out size of final rbm\n",
    "mlp_batch_size\t\t= 10 # dont change\n",
    "mlp_learn_rate\t\t= 0.05\n",
    "mlp_training_epochs = 100\n",
    "mlp_report_freq\t\t= 1\n",
    "mlp_report_buffer\t= mlp_training_epochs\n",
    "```\n",
    "\n",
    "shit to try:\n",
    "- multiple rbm\n",
    "\n",
    "## Questions\n",
    "\n",
    "why rbm instead of more hidden layers? i thought those created abstractions\n",
    "\n",
    "## Strategy\n",
    "\n",
    "Grid search\n",
    "\n",
    "Heatmap, write a function to record different hyperparameters\n",
    "\n",
    "RBM Hidden Size    | MLP Hidden Nodes\n",
    "--------|------\n",
    "x     | 500 | 1000\n",
    "10     | 50% | 5%\n",
    "50   | 75% | 25%\n",
    "\n",
    "visualize heatmap\n",
    "https://stackoverflow.com/questions/33282368/plotting-a-2d-heatmap-with-matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from Mnist import *\n",
    "from Supervised import *\n",
    "from Unsupervised import *\n",
    "import numpy as np\n",
    "np.set_printoptions( precision = 3, suppress = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def wrapped():\n",
    "    \"\"\"wrapper for testing\"\"\"\n",
    "    # General settings (you CAN change these):\n",
    "    mnist_use_threshold = False\n",
    "\n",
    "    # RBM hyperparameters (you CAN change these):\n",
    "    rbm_is_continuous\t= True\n",
    "    rbm_visible_size\t= 784\n",
    "    rbm_hidden_size\t\t= 50\n",
    "    rbm_batch_size\t\t= 10\n",
    "    rbm_learn_rate\t\t= 0.01\n",
    "    rbm_cd_steps\t\t= 1\n",
    "    rbm_training_epochs = 100\n",
    "    rbm_report_freq\t\t= 1\n",
    "    rbm_report_buffer\t= rbm_training_epochs\n",
    "\n",
    "    # MLP hyperparameters (you CAN change these):\n",
    "    # more than 2 to 3 layers is prob not helpful\n",
    "    mlp_layer_sizes\t\t= [ rbm_hidden_size, 20, 10 ] \n",
    "    # always last is 10, always first is equal to out size of final rbm\n",
    "    mlp_batch_size\t\t= 10 # dont change\n",
    "    # mlp_learn_rate\t\t= 0.05\n",
    "    mlp_learn_rate\t\t= 0.10\n",
    "    # mlp_training_epochs = 100\n",
    "    mlp_training_epochs = 10\n",
    "    mlp_report_freq\t\t= 1\n",
    "    mlp_report_buffer\t= mlp_training_epochs\n",
    "\n",
    "    # MNIST training example counts (you CANNOT change these):\n",
    "    mnist_num_training_examples\t  = 10000\n",
    "    mnist_num_validation_examples =\t 5000\n",
    "    mnist_num_testing_examples\t  =\t 5000\n",
    "\n",
    "    # Load MNIST dataset:\n",
    "    mnist = Mnist( mnist_use_threshold )\n",
    "\n",
    "    training_digits,   training_labels\t = mnist.getTrainingData( mnist_num_training_examples )\n",
    "    validation_digits, validation_labels = mnist.getValidationData( mnist_num_validation_examples )\n",
    "    testing_digits,\t   testing_labels\t = mnist.getTestingData( mnist_num_testing_examples )\n",
    "\n",
    "    # Initialize and train RBM:\n",
    "    rbm_name = 'rbm_' + str(rbm_visible_size) + '_' + str(rbm_hidden_size)\n",
    "    rbm = Rbm( rbm_name, rbm_visible_size, rbm_hidden_size, rbm_is_continuous )\n",
    "    rbm.train( training_digits, validation_digits, rbm_learn_rate, rbm_cd_steps, rbm_training_epochs, rbm_batch_size, rbm_report_freq, rbm_report_buffer )\n",
    "\n",
    "    # Encode datasets with RBM:\n",
    "    _, training_encodings = rbm.getHiddenSample( training_digits )\n",
    "    _, validation_encodings = rbm.getHiddenSample( validation_digits )\n",
    "    _, testing_encodings = rbm.getHiddenSample( testing_digits )\n",
    "\n",
    "    # Initialize and train MLP:\n",
    "    mlp_name = 'mlp_' + '_'.join( str(i) for i in mlp_layer_sizes )\n",
    "    mlp = Mlp( mlp_name, mlp_layer_sizes, 'sigmoid' )\n",
    "    mlp.train( training_encodings, training_labels, validation_encodings, validation_labels, mlp_learn_rate, mlp_training_epochs, mlp_batch_size, mlp_report_freq, mlp_report_buffer )\n",
    "\n",
    "    # Perform final test:\n",
    "    testing_guesses = mlp.predict( testing_encodings )\n",
    "    testing_error = mlp.getErrorRate( testing_labels, testing_guesses )\n",
    "    testing_accuracy = mnist_get_accuracy( testing_labels, testing_guesses )\n",
    "    return testing_error, testing_accuracy\n",
    "#     print ('Final Testing Error Rate: %f' % ( testing_error ))\n",
    "#     print ('Final Testing Accuracy: %f' % ( testing_accuracy ))\n",
    "\n",
    "%timeit wrapped()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
